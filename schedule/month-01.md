| Week | Monday                    | Tuesday                       | Wednesday                     | Thursday                     | Friday                     |
|------|----------------------------|--------------------------------|-------------------------------|-------------------------------|-----------------------------|
| 1    | Read first half of the Attention Is All You Need paper  | Read second half of the Attention Is All You Need paper, watch introductory videos and tutorials | Continue watching videos and tutorials, read in-depth tutorials | Experiment with code examples, think about small project | Review what you've learned, research resources for small project |
| 2    | Dive deeper into the details of how transformers work | Begin working on a small project | Continue working on small project | Continue working on small project | Continue working on small project |
| 3    | Read the BERT paper to understand how pre-training can be used to improve transformer-based models | Experiment with fine-tuning pre-trained transformer models | Look at real-world examples of transformer models in NLP systems | Experiment with different pre-trained models | Review what you've learned and think about next steps|
| 4    | Continue experimenting with pre-trained models | Work on more complex NLP task using attention-based models | Continue working on complex NLP task | Continue working on complex NLP task | Review what you've learned, plan for next steps |
